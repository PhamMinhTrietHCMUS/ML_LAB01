{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a28ed18",
   "metadata": {},
   "source": [
    "# Appliances Energy Consumption Prediction - Regression Analysis\n",
    "\n",
    "## Project Overview\n",
    "This notebook implements multiple regression models to predict appliances energy consumption in a low-energy house based on environmental sensors data (temperature, humidity) and weather conditions.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "### Why Energy Consumption Prediction Matters?\n",
    "\n",
    "Energy consumption prediction is crucial in today's world for several important reasons:\n",
    "\n",
    "**1. Smart Home Optimization**\n",
    "- Enable intelligent home automation systems to optimize energy usage\n",
    "- Automatically adjust heating, cooling, and appliance operation\n",
    "- Reduce unnecessary energy waste through predictive control\n",
    "\n",
    "**2. Cost Savings for Households**\n",
    "- Help homeowners understand and reduce their electricity bills\n",
    "- Identify high-consumption periods and patterns\n",
    "- Make informed decisions about appliance usage\n",
    "\n",
    "**3. Grid Management and Sustainability**\n",
    "- Improve electrical grid load forecasting\n",
    "- Balance energy supply and demand more efficiently\n",
    "- Support renewable energy integration\n",
    "\n",
    "**4. Environmental Impact**\n",
    "- Reduce carbon footprint by minimizing energy waste\n",
    "- Contribute to climate change mitigation efforts\n",
    "- Promote sustainable living practices\n",
    "\n",
    "### Problem Definition\n",
    "\n",
    "**Objective:** Predict appliances energy consumption (in Wh) in a low-energy house\n",
    "\n",
    "**Input Features:**\n",
    "- **Environmental Sensors:** Temperature and humidity readings from various rooms\n",
    "- **Weather Data:** External temperature, humidity, wind speed, visibility, pressure\n",
    "- **Temporal Information:** Date and time patterns\n",
    "\n",
    "**Target Variable:**\n",
    "- Appliances energy consumption (Wh)\n",
    "\n",
    "**Why This Matters:**\n",
    "This analysis helps understand how environmental conditions affect energy consumption patterns, enabling:\n",
    "- Better home energy management\n",
    "- Data-driven decisions for energy efficiency improvements\n",
    "- Predictive maintenance and optimization strategies\n",
    "- Insights for smart building design\n",
    "\n",
    "By accurately predicting energy consumption, we can create more sustainable and cost-effective living environments while reducing environmental impact.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "**Dataset Name:** Appliances Energy Prediction Dataset\n",
    "\n",
    "**Source:** UCI Machine Learning Repository\n",
    "\n",
    "**Time Period:** January 11, 2016 to May 27, 2016 (4.5 months)\n",
    "\n",
    "**Number of Samples:** 19,735 instances (10-minute intervals)\n",
    "\n",
    "**Number of Features:** 28 variables (26 features + 1 target + 1 timestamp)\n",
    "\n",
    "### Feature Details:\n",
    "\n",
    "| Variable Name | Role | Type | Description | Units | Missing Values |\n",
    "|---------------|------|------|-------------|-------|----------------|\n",
    "| date | Identifier | Datetime | Timestamp of measurement | yyyy-mm-dd hh:mm:ss | No |\n",
    "| **Appliances** | **Target** | **Continuous** | **Energy consumption of appliances** | **Wh** | **No** |\n",
    "| lights | Feature | Continuous | Energy consumption of lights | Wh | No |\n",
    "| T1 | Feature | Continuous | Temperature in kitchen | °C | No |\n",
    "| RH_1 | Feature | Continuous | Humidity in kitchen | % | No |\n",
    "| T2 | Feature | Continuous | Temperature in living room | °C | No |\n",
    "| RH_2 | Feature | Continuous | Humidity in living room | % | No |\n",
    "| T3 | Feature | Continuous | Temperature in laundry room | °C | No |\n",
    "| RH_3 | Feature | Continuous | Humidity in laundry room | % | No |\n",
    "| T4 | Feature | Continuous | Temperature in office room | °C | No |\n",
    "| RH_4 | Feature | Continuous | Humidity in office room | % | No |\n",
    "| T5 | Feature | Continuous | Temperature in bathroom | °C | No |\n",
    "| RH_5 | Feature | Continuous | Humidity in bathroom | % | No |\n",
    "| T6 | Feature | Continuous | Temperature outside (north side) | °C | No |\n",
    "| RH_6 | Feature | Continuous | Humidity outside (north side) | % | No |\n",
    "| T7 | Feature | Continuous | Temperature in ironing room | °C | No |\n",
    "| RH_7 | Feature | Continuous | Humidity in ironing room | % | No |\n",
    "| T8 | Feature | Continuous | Temperature in teenager room | °C | No |\n",
    "| RH_8 | Feature | Continuous | Humidity in teenager room | % | No |\n",
    "| T9 | Feature | Continuous | Temperature in parents room | °C | No |\n",
    "| RH_9 | Feature | Continuous | Humidity in parents room | % | No |\n",
    "| T_out | Feature | Continuous | Temperature outside (weather station) | °C | No |\n",
    "| Press_mm_hg | Feature | Continuous | Atmospheric pressure | mm Hg | No |\n",
    "| RH_out | Feature | Continuous | Humidity outside (weather station) | % | No |\n",
    "| Windspeed | Feature | Continuous | Wind speed | m/s | No |\n",
    "| Visibility | Feature | Continuous | Visibility | km | No |\n",
    "| Tdewpoint | Feature | Continuous | Dew point temperature | °C | No |\n",
    "\n",
    "### Dataset Characteristics:\n",
    "- **Complete Dataset:** No missing values\n",
    "- **High Frequency:** Measurements every 10 minutes\n",
    "- **Real House:** Actual smart home in Belgium\n",
    "- **Low-Energy House:** Modern energy-efficient building\n",
    "- **Multi-Sensor:** 9 temperature sensors, 9 humidity sensors\n",
    "- **Weather Integration:** External weather data from nearby station\n",
    "\n",
    "### House Specifications:\n",
    "- **Location:** Belgium\n",
    "- **Type:** Low-energy residential house\n",
    "- **Monitoring Period:** 4.5 months (winter to spring)\n",
    "- **Energy System:** Modern appliances with energy monitoring\n",
    "- **Sensor Network:** Wireless ZigBee sensor network\n",
    "\n",
    "### Target Variable Statistics:\n",
    "- **Mean Appliances Consumption:** ~97.7 Wh\n",
    "- **Range:** 10-1,080 Wh\n",
    "- **Standard Deviation:** ~102.8 Wh\n",
    "- **Peak Usage:** During cooking, washing, and entertainment activities\n",
    "\n",
    "### Feature Categories:\n",
    "1. **Internal Climate (18 sensors):**\n",
    "   - Temperature sensors in 9 different rooms\n",
    "   - Humidity sensors in 9 different rooms\n",
    "\n",
    "2. **External Weather (6 variables):**\n",
    "   - Outside temperature\n",
    "   - Outside humidity\n",
    "   - Atmospheric pressure\n",
    "   - Wind speed\n",
    "   - Visibility\n",
    "   - Dew point\n",
    "\n",
    "3. **Lighting:**\n",
    "   - Separate energy consumption of lights\n",
    "\n",
    "### Time Series Characteristics:\n",
    "- **Temporal Patterns:** Daily and weekly cycles\n",
    "- **Seasonal Effects:** Winter to spring transition\n",
    "- **Occupancy Patterns:** Human activity influence\n",
    "- **Weather Correlation:** External conditions impact\n",
    "\n",
    "### Application Areas:\n",
    "- Smart home energy management systems\n",
    "- Load forecasting for residential buildings\n",
    "- Energy efficiency optimization\n",
    "- IoT and sensor network applications\n",
    "- Building automation systems\n",
    "- Demand response programs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef1815",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1bee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "csv_filename = '../data_set/energydata_complete.csv' \n",
    "\n",
    "notebook_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in dir() else os.getcwd()\n",
    "csv_path = os.path.join(notebook_dir, csv_filename)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"Loaded file: {csv_filename}\")\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589d7b6",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ab9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=1, how='all')\n",
    "df = df.drop(columns='date           ', axis=1)\n",
    "\n",
    "print(\"Column Names:\", df.columns.tolist())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nNumber of duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "df = df.fillna(method='ffill').fillna(df.mean())\n",
    "\n",
    "target_candidates = [' Appliances']\n",
    "target_col = ' Appliances'\n",
    "\n",
    "for candidate in target_candidates:\n",
    "    if candidate in df.columns:\n",
    "        target_col = candidate\n",
    "        break\n",
    "\n",
    "print(f\"\\nTarget column: {target_col}\")\n",
    "\n",
    "X = df.drop(target_col, axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "X = X[numeric_cols]\n",
    "\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b71c82",
   "metadata": {},
   "source": [
    "## 3. Build Multiple Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0, random_state=42),\n",
    "    'Lasso Regression': Lasso(alpha=0.1, random_state=42),\n",
    "    'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "predictions = {}\n",
    "\n",
    "# All models here are linear (we trained on standardized inputs)\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    trained_models[name] = model\n",
    "    predictions[name] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee5f828",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation - Regression Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b91791",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, y_pred in predictions.items():\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    n = len(y_test)\n",
    "    p = X_test.shape[1]\n",
    "    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'R²': r2,\n",
    "        'Adjusted R²': adj_r2,\n",
    "        'MAPE (%)': mape\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('R²', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\" * 100)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8984c988",
   "metadata": {},
   "source": [
    "## 5. Performance Comparison Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d475b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "sorted_r2 = results_df.sort_values('R²')\n",
    "bars1 = ax1.barh(sorted_r2['Model'], sorted_r2['R²'], color='skyblue', edgecolor='navy')\n",
    "ax1.set_xlabel('R² Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('R² Score Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlim(0, 1)\n",
    "for i, bar in enumerate(bars1):\n",
    "    width = bar.get_width()\n",
    "    ax1.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.4f}', ha='left', va='center', fontsize=10)\n",
    "\n",
    "ax2 = axes[0, 1]\n",
    "sorted_rmse = results_df.sort_values('RMSE', ascending=False)\n",
    "bars2 = ax2.barh(sorted_rmse['Model'], sorted_rmse['RMSE'], color='lightcoral', edgecolor='darkred')\n",
    "ax2.set_xlabel('RMSE (Wh)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('RMSE Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "for i, bar in enumerate(bars2):\n",
    "    width = bar.get_width()\n",
    "    ax2.text(width + 0.2, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.2f}', ha='left', va='center', fontsize=10)\n",
    "\n",
    "ax3 = axes[1, 0]\n",
    "sorted_mae = results_df.sort_values('MAE', ascending=False)\n",
    "bars3 = ax3.barh(sorted_mae['Model'], sorted_mae['MAE'], color='lightgreen', edgecolor='darkgreen')\n",
    "ax3.set_xlabel('MAE (Wh)', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('MAE Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "for i, bar in enumerate(bars3):\n",
    "    width = bar.get_width()\n",
    "    ax3.text(width + 0.15, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.2f}', ha='left', va='center', fontsize=10)\n",
    "\n",
    "ax4 = axes[1, 1]\n",
    "sorted_mape = results_df.sort_values('MAPE (%)', ascending=False)\n",
    "bars4 = ax4.barh(sorted_mape['Model'], sorted_mape['MAPE (%)'], color='plum', edgecolor='purple')\n",
    "ax4.set_xlabel('MAPE (%)', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('MAPE Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "for i, bar in enumerate(bars4):\n",
    "    width = bar.get_width()\n",
    "    ax4.text(width + 0.2, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.2f}%', ha='left', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_model_name = results_df.iloc[0]['Model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bb7985",
   "metadata": {},
   "source": [
    "## 6. Predicted vs Actual Values Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs Actual plots (dynamic layout matching number of models)\n",
    "n = len(predictions)\n",
    "if n == 0:\n",
    "    print(\"No model predictions available to plot.\")\n",
    "else:\n",
    "    ncols = min(4, n)\n",
    "    nrows = int(np.ceil(n / ncols))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(5 * ncols, 4 * nrows))\n",
    "\n",
    "    # Normalize axes to a flat array for easy indexing\n",
    "    if isinstance(axes, np.ndarray):\n",
    "        axes_flat = axes.flatten()\n",
    "    else:\n",
    "        axes_flat = np.array([axes])\n",
    "\n",
    "    idx = -1\n",
    "    for idx, (name, y_pred) in enumerate(predictions.items()):\n",
    "        ax = axes_flat[idx]\n",
    "        ax.scatter(y_test, y_pred, alpha=0.5, s=30, edgecolors='k', linewidth=0.5)\n",
    "\n",
    "        min_val = min(y_test.min(), y_pred.min())\n",
    "        max_val = max(y_test.max(), y_pred.max())\n",
    "        ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "\n",
    "        ax.set_xlabel('Actual Appliances (Wh)', fontsize=10, fontweight='bold')\n",
    "        ax.set_ylabel('Predicted Appliances (Wh)', fontsize=10, fontweight='bold')\n",
    "        ax.set_title(f'{name}\\nR² = {results_df[results_df[\"Model\"]==name][\"R²\"].values[0]:.4f}', \n",
    "                     fontsize=11, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for extra_ax in axes_flat[idx+1:]:\n",
    "        fig.delaxes(extra_ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c766ce",
   "metadata": {},
   "source": [
    "## 7. Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea0a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = results_df.head(4)['Model'].tolist()\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 5))\n",
    "\n",
    "for idx, model_name in enumerate(top_models):\n",
    "    ax = axes[idx]\n",
    "    y_pred = predictions[model_name]\n",
    "    residuals = y_test - y_pred\n",
    "    \n",
    "    ax.scatter(y_pred, residuals, alpha=0.5, s=30, edgecolors='k', linewidth=0.5)\n",
    "    ax.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "    ax.set_xlabel('Predicted Values (Wh)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Residuals (Wh)', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{model_name}\\nResidual Plot', fontsize=12, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7245629c",
   "metadata": {},
   "source": [
    "## 9. Coefficients Analysis (for Linear Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36bafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_models_list = ['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'ElasticNet']\n",
    "\n",
    "coef_data = []\n",
    "for model_name in linear_models_list:\n",
    "    model = trained_models[model_name]\n",
    "    coef_data.append(model.coef_)\n",
    "\n",
    "coef_df = pd.DataFrame(coef_data, columns=X.columns, index=linear_models_list)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"COEFFICIENTS FOR LINEAR MODELS (Standardized)\")\n",
    "print(\"=\" * 100)\n",
    "print(coef_df.T.to_string())\n",
    "print(\"=\" * 100)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, model_name in enumerate(linear_models_list):\n",
    "    ax = axes[idx]\n",
    "    coefs = coef_df.loc[model_name].sort_values()\n",
    "    colors = ['red' if x < 0 else 'green' for x in coefs]\n",
    "    \n",
    "    bars = ax.barh(coefs.index, coefs.values, color=colors, edgecolor='black')\n",
    "    ax.set_xlabel('Coefficient Value', fontsize=11, fontweight='bold')\n",
    "    ax.set_title(f'{model_name}\\nCoefficients', fontsize=12, fontweight='bold')\n",
    "    ax.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        offset = 0.5 if width > 0 else -0.5\n",
    "        ax.text(width + offset, bar.get_y() + bar.get_height()/2, \n",
    "                f'{width:.2f}', ha='left' if width > 0 else 'right', \n",
    "                va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef283270",
   "metadata": {},
   "source": [
    "## 10. Interpretation of Results\n",
    "\n",
    "### 10.1 Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620e6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"COMPREHENSIVE MODEL INTERPRETATION\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "best_model = results_df.iloc[0]\n",
    "worst_model = results_df.iloc[-1]\n",
    "\n",
    "print(\"\\nPERFORMANCE RANKING:\")\n",
    "print(\"-\" * 100)\n",
    "for i, row in results_df.iterrows():\n",
    "    print(f\"{i+1}. {row['Model']:<25} | R²: {row['R²']:.4f} | RMSE: {row['RMSE']:.3f} | MAE: {row['MAE']:.3f}\")\n",
    "\n",
    "print(\"\\n\\nBEST MODEL ANALYSIS:\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"Model: {best_model['Model']}\")\n",
    "print(f\"  • R² Score: {best_model['R²']:.4f}\")\n",
    "print(f\"    → Explains {best_model['R²']*100:.2f}% of variance in appliances energy consumption\")\n",
    "print(f\"  • RMSE: {best_model['RMSE']:.3f} Wh\")\n",
    "print(f\"    → Average prediction error magnitude\")\n",
    "print(f\"  • MAE: {best_model['MAE']:.3f} Wh\")\n",
    "print(f\"    → Average absolute prediction error\")\n",
    "print(f\"  • MAPE: {best_model['MAPE (%)']:.2f}%\")\n",
    "print(f\"    → Average percentage error in predictions\")\n",
    "\n",
    "print(\"\\n\\nWORST MODEL ANALYSIS:\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"Model: {worst_model['Model']}\")\n",
    "print(f\"  • R² Score: {worst_model['R²']:.4f}\")\n",
    "print(f\"    → Explains only {worst_model['R²']*100:.2f}% of variance\")\n",
    "print(f\"  • RMSE: {worst_model['RMSE']:.3f} Wh\")\n",
    "print(f\"  • MAE: {worst_model['MAE']:.3f} Wh\")\n",
    "\n",
    "# Model category comparison (linear-only)\n",
    "print(\"\\n\\nMODEL TYPE COMPARISON:\")\n",
    "print(\"-\" * 100)\n",
    "linear_avg_r2 = results_df[results_df['Model'].isin(linear_models_list)]['R²'].mean()\n",
    "\n",
    "print(f\"Linear Models Average R²: {linear_avg_r2:.4f}\")\n",
    "print(\"\\n✓ Note: Non-linear/tree-based models removed — analysis focuses on linear models and their coefficients.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07eba65",
   "metadata": {},
   "source": [
    "### 10.2 Coefficient and Feature Importance Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"FEATURE IMPACT INTERPRETATION\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "lr_model = trained_models['Linear Regression']\n",
    "lr_coefs = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': lr_model.coef_\n",
    "}).sort_values('Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nLINEAR REGRESSION COEFFICIENTS INTERPRETATION:\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for _, row in lr_coefs.iterrows():\n",
    "    feature = row['Feature']\n",
    "    coef = row['Coefficient']\n",
    "    direction = \"INCREASES\" if coef > 0 else \"DECREASES\"\n",
    "    \n",
    "    print(f\"{feature}:\")\n",
    "    print(f\"  Coefficient: {coef:+.4f}\")\n",
    "    print(f\"  One standard deviation increase in {feature} {direction} appliances energy consumption by {abs(coef):.4f} std units\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\\nKEY INSIGHTS FROM COEFFICIENT ANALYSIS:\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# Top features by absolute coefficient magnitude (linear models)\n",
    "top_3_features = lr_coefs.reindex(lr_coefs['Coefficient'].abs().sort_values(ascending=False).index).head(3)['Feature'].tolist()\n",
    "print(f\"Top 3 Most Important Features (by coefficient magnitude): {', '.join(top_3_features)}\")\n",
    "\n",
    "positive_coefs = lr_coefs[lr_coefs['Coefficient'] > 0]\n",
    "negative_coefs = lr_coefs[lr_coefs['Coefficient'] < 0]\n",
    "\n",
    "print(f\"\\nFeatures with POSITIVE impact on appliances consumption ({len(positive_coefs)}):\")\n",
    "for _, row in positive_coefs.iterrows():\n",
    "    print(f\"  {row['Feature']} ({row['Coefficient']:+.4f})\")\n",
    "\n",
    "print(f\"\\nFeatures with NEGATIVE impact on appliances consumption ({len(negative_coefs)}):\")\n",
    "for _, row in negative_coefs.iterrows():\n",
    "    print(f\"  {row['Feature']} ({row['Coefficient']:+.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e28044",
   "metadata": {},
   "source": [
    "### 10.3 Model Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"MODEL QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    model_name = row['Model']\n",
    "    r2 = row['R²']\n",
    "    rmse = row['RMSE']\n",
    "    mape = row['MAPE (%)']\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"MODEL: {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # R² interpretation\n",
    "    print(f\"\\n1. R² Score: {r2:.4f}\")\n",
    "    if r2 >= 0.9:\n",
    "        quality = \"EXCELLENT\"\n",
    "        interpretation = \"Model explains >90% of variance - very strong predictive power\"\n",
    "    elif r2 >= 0.8:\n",
    "        quality = \"GOOD\"\n",
    "        interpretation = \"Model explains 80-90% of variance - strong predictive power\"\n",
    "    elif r2 >= 0.7:\n",
    "        quality = \"MODERATE\"\n",
    "        interpretation = \"Model explains 70-80% of variance - acceptable predictive power\"\n",
    "    elif r2 >= 0.5:\n",
    "        quality = \"FAIR\"\n",
    "        interpretation = \"Model explains 50-70% of variance - limited predictive power\"\n",
    "    else:\n",
    "        quality = \"POOR\"\n",
    "        interpretation = \"Model explains <50% of variance - weak predictive power\"\n",
    "    \n",
    "    print(f\"   Quality: {quality}\")\n",
    "    print(f\"   → {interpretation}\")\n",
    "    \n",
    "    # RMSE interpretation\n",
    "    print(f\"\\n2. RMSE: {rmse:.3f} Wh\")\n",
    "    avg_appliance = y_test.mean()\n",
    "    rmse_percentage = (rmse / avg_appliance) * 100\n",
    "    print(f\"   → Average prediction error: {rmse:.3f} Wh ({rmse_percentage:.2f}% of mean appliances consumption)\")\n",
    "    \n",
    "    if rmse_percentage < 10:\n",
    "        print(f\"   → Error is <10% of mean - HIGH PRECISION\")\n",
    "    elif rmse_percentage < 15:\n",
    "        print(f\"   → Error is 10-15% of mean - GOOD PRECISION\")\n",
    "    elif rmse_percentage < 20:\n",
    "        print(f\"   → Error is 15-20% of mean - MODERATE PRECISION\")\n",
    "    else:\n",
    "        print(f\"   → Error is >20% of mean - LOW PRECISION\")\n",
    "    \n",
    "    # MAPE interpretation\n",
    "    print(f\"\\n3. MAPE: {mape:.2f}%\")\n",
    "    if mape < 10:\n",
    "        print(f\"   → Highly accurate forecasting\")\n",
    "    elif mape < 20:\n",
    "        print(f\"   → Good forecasting\")\n",
    "    elif mape < 30:\n",
    "        print(f\"   → Reasonable forecasting\")\n",
    "    else:\n",
    "        print(f\"   → Inaccurate forecasting\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178430f5",
   "metadata": {},
   "source": [
    "## 11. Interactive Prediction Application\n",
    "\n",
    "### 11.1 Setup Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d660e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model for the application\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "# Check if it's a linear model (needs scaling)\n",
    "is_linear_model = best_model_name in ['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'ElasticNet']\n",
    "\n",
    "print(f\"  Selected Model for Application: {best_model_name}\")\n",
    "print(f\"   R² Score: {results_df.iloc[0]['R²']:.4f}\")\n",
    "print(f\"   RMSE: {results_df.iloc[0]['RMSE']:.3f}\")\n",
    "print(f\"   MAE: {results_df.iloc[0]['MAE']:.3f}\")\n",
    "print(f\"\\n  Number of features: {X.shape[1]}\")\n",
    "print(f\"   Feature names: {list(X.columns)}\")\n",
    "\n",
    "# Define generic prediction function - works with any number of features\n",
    "def predict_value(*args):\n",
    "    \"\"\"\n",
    "    Predict target based on input features (flexible for any dataset).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    *args: Feature values in the same order as X columns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Predicted value\n",
    "    \"\"\"\n",
    "    # Create input array with correct number of features\n",
    "    input_data = np.array([list(args)])\n",
    "    \n",
    "    # Scale if needed\n",
    "    if is_linear_model:\n",
    "        input_data_scaled = scaler.transform(input_data)\n",
    "        prediction = best_model.predict(input_data_scaled)[0]\n",
    "    else:\n",
    "        prediction = best_model.predict(input_data)[0]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Test with first row of test set\n",
    "print(f\"\\n✓ Test Prediction:\")\n",
    "test_sample = X_test.iloc[0].values\n",
    "test_prediction = predict_value(*test_sample)\n",
    "actual_value = y_test.iloc[0]\n",
    "\n",
    "print(f\"   Predicted value: {test_prediction:.4f}\")\n",
    "print(f\"   Actual value: {actual_value:.4f}\")\n",
    "print(f\"   Error: {abs(test_prediction - actual_value):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014250bd",
   "metadata": {},
   "source": [
    "### 11.2 Interactive Widget Interface (using ipywidgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19482b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, HTML, clear_output\n",
    "except ImportError:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install ipywidgets\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, HTML, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44309a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"INTERACTIVE PREDICTION APPLICATION\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"Model: {best_model_name} | R² = {results_df.iloc[0]['R²']:.4f} | RMSE = {results_df.iloc[0]['RMSE']:.4f}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Create sliders dynamically based on actual data\n",
    "sliders = {}\n",
    "for col in X.columns:\n",
    "    min_val = X[col].min()\n",
    "    max_val = X[col].max()\n",
    "    mean_val = X[col].mean()\n",
    "    step = (max_val - min_val) / 100\n",
    "    \n",
    "    sliders[col] = widgets.FloatSlider(\n",
    "        value=mean_val,\n",
    "        min=min_val,\n",
    "        max=max_val,\n",
    "        step=step,\n",
    "        description=f'{col}:',\n",
    "        style={'description_width': '150px'},\n",
    "        layout=widgets.Layout(width='600px')\n",
    "    )\n",
    "\n",
    "# Output widget\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# Prediction button\n",
    "predict_button = widgets.Button(\n",
    "    description='Make Prediction',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='40px'),\n",
    "    style={'font_weight': 'bold'}\n",
    ")\n",
    "\n",
    "# Reset button\n",
    "reset_button = widgets.Button(\n",
    "    description='Reset to Mean',\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "def on_predict_click(b):\n",
    "    with output_widget:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Get all slider values\n",
    "        input_values = [sliders[col].value for col in X.columns]\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = predict_value(*input_values)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"=\" * 80)\n",
    "        print(\"PREDICTION RESULTS\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\nPredicted Output: {prediction:.4f}\\n\")\n",
    "        print(\"Input Values:\")\n",
    "        for col, val in zip(X.columns, input_values):\n",
    "            print(f\"   {col}: {val:.4f}\")\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "def on_reset_click(b):\n",
    "    for col in X.columns:\n",
    "        sliders[col].value = X[col].mean()\n",
    "    with output_widget:\n",
    "        clear_output()\n",
    "        print(\"Reset to mean values.\")\n",
    "\n",
    "predict_button.on_click(on_predict_click)\n",
    "reset_button.on_click(on_reset_click)\n",
    "\n",
    "# Display all sliders\n",
    "display(HTML(\"<h3>Input Features:</h3>\"))\n",
    "for col, slider in sliders.items():\n",
    "    display(slider)\n",
    "display(HTML(\"<br>\"))\n",
    "display(widgets.HBox([predict_button, reset_button]))\n",
    "display(HTML(\"<br>\"))\n",
    "display(output_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b131b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfe3696b",
   "metadata": {},
   "source": [
    "### 11.3 Feature Sensitivity Analysis Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3feda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"FEATURE SENSITIVITY ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Dropdown to select feature\n",
    "feature_dropdown = widgets.Dropdown(\n",
    "    options=list(X.columns),\n",
    "    value=X.columns[0],\n",
    "    description='Select Feature:',\n",
    "    style={'description_width': '120px'}\n",
    ")\n",
    "\n",
    "# Output for sensitivity plot\n",
    "sensitivity_output = widgets.Output()\n",
    "\n",
    "def analyze_sensitivity(feature_name):\n",
    "    with sensitivity_output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Base values (mean from training data)\n",
    "        base_values = X.mean().to_dict()\n",
    "        \n",
    "        # Get range for selected feature\n",
    "        min_val = X[feature_name].min()\n",
    "        max_val = X[feature_name].max()\n",
    "        feature_range = np.linspace(min_val, max_val, 50)\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        # Vary selected feature while keeping others at mean\n",
    "        for value in feature_range:\n",
    "            input_vals = base_values.copy()\n",
    "            input_vals[feature_name] = value\n",
    "            \n",
    "            pred = predict_value(*[input_vals[col] for col in X.columns])\n",
    "            predictions.append(pred)\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.plot(feature_range, predictions, linewidth=3, color='darkblue', marker='o', markersize=4)\n",
    "        ax.set_xlabel(f'{feature_name}', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Predicted Output', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(f'Sensitivity Analysis: Impact of {feature_name}', fontsize=14, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add baseline marker\n",
    "        base_pred = predictions[len(predictions)//2]\n",
    "        ax.axhline(y=base_pred, color='red', linestyle='--', alpha=0.5, \n",
    "                  label=f'Baseline: {base_pred:.4f}')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nSensitivity Statistics for {feature_name}:\")\n",
    "        print(f\"   Min Predicted Value: {min(predictions):.4f}\")\n",
    "        print(f\"   Max Predicted Value: {max(predictions):.4f}\")\n",
    "        print(f\"   Range of Impact: {max(predictions) - min(predictions):.4f}\")\n",
    "        print(f\"   Baseline Value: {base_pred:.4f}\")\n",
    "        \n",
    "        if predictions[-1] > predictions[0]:\n",
    "            trend = \"INCREASES\"\n",
    "        else:\n",
    "            trend = \"DECREASES\"\n",
    "        \n",
    "        print(f\"\\nTrend: Output {trend} as {feature_name} increases\")\n",
    "\n",
    "def on_feature_change(change):\n",
    "    analyze_sensitivity(change['new'])\n",
    "\n",
    "feature_dropdown.observe(on_feature_change, names='value')\n",
    "\n",
    "display(HTML(\"<h3>Interactive Sensitivity Analysis:</h3>\"))\n",
    "display(HTML(\"<p>Select a feature to see how it affects the prediction</p>\"))\n",
    "display(feature_dropdown)\n",
    "display(sensitivity_output)\n",
    "\n",
    "analyze_sensitivity(X.columns[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05fbfa",
   "metadata": {},
   "source": [
    "### 11.4 Model Performance Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e584b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"MODEL PERFORMANCE DASHBOARD\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "gs = fig.add_gridspec(3, 3, hspace=1.0, wspace=0.3)\n",
    "\n",
    "# 1. Model Comparison - R² Score\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "sorted_models = results_df.sort_values('R²', ascending=True)\n",
    "colors_gradient = plt.cm.viridis(np.linspace(0.3, 0.9, len(sorted_models)))\n",
    "bars = ax1.barh(sorted_models['Model'], sorted_models['R²'], color=colors_gradient, edgecolor='black')\n",
    "ax1.set_xlabel('R² Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Model Performance Comparison (R² Score)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.legend()\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax1.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.4f}', ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 2. Error Distribution - RMSE and MAE\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "x_pos = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "ax2.bar(x_pos - width/2, results_df['RMSE'], width, label='RMSE', color='coral', edgecolor='black')\n",
    "ax2.bar(x_pos + width/2, results_df['MAE'], width, label='MAE', color='lightblue', edgecolor='black')\n",
    "ax2.set_ylabel('Error (Wh)', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Error Metrics Comparison', fontsize=12, fontweight='bold')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(results_df['Model'], rotation=45, ha='right', fontsize=8)\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. MAPE Distribution\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.bar(results_df['Model'], results_df['MAPE (%)'], color='lightgreen', edgecolor='black')\n",
    "ax3.set_ylabel('MAPE (%)', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Mean Absolute Percentage Error', fontsize=12, fontweight='bold')\n",
    "ax3.tick_params(axis='x', rotation=45, labelsize=8)\n",
    "ax3.axhline(y=10, color='red', linestyle='--', alpha=0.5, label='10% threshold')\n",
    "ax3.legend()\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Adjusted R²\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "colors_r2 = ['green' if x >= 0.8 else 'orange' if x >= 0.6 else 'red' \n",
    "             for x in results_df['Adjusted R²']]\n",
    "ax4.bar(results_df['Model'], results_df['Adjusted R²'], color=colors_r2, edgecolor='black')\n",
    "ax4.set_ylabel('Adjusted R²', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('Adjusted R² Score', fontsize=12, fontweight='bold')\n",
    "ax4.tick_params(axis='x', rotation=45, labelsize=8)\n",
    "ax4.set_ylim(0, 1)\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Best Model Prediction Distribution\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "best_pred = predictions[best_model_name]\n",
    "residuals_best = y_test - best_pred\n",
    "ax5.hist(residuals_best, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "ax5.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "ax5.set_xlabel('Residual (Wh)', fontsize=11, fontweight='bold')\n",
    "ax5.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax5.set_title(f'{best_model_name}\\nResidual Distribution', fontsize=12, fontweight='bold')\n",
    "ax5.legend()\n",
    "ax5.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 6. Prediction Accuracy\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "best_pred = predictions[best_model_name]\n",
    "ax6.scatter(y_test, best_pred, alpha=0.6, edgecolors='k', linewidth=0.5, s=40)\n",
    "min_val = min(y_test.min(), best_pred.min())\n",
    "max_val = max(y_test.max(), best_pred.max())\n",
    "ax6.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "ax6.set_xlabel('Actual Appliances (Wh)', fontsize=11, fontweight='bold')\n",
    "ax6.set_ylabel('Predicted Appliances (Wh)', fontsize=11, fontweight='bold')\n",
    "ax6.set_title(f'{best_model_name}\\nPredicted vs Actual', fontsize=12, fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.suptitle('COMPREHENSIVE MODEL PERFORMANCE DASHBOARD', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nRecommended Model for Production: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50729800",
   "metadata": {},
   "source": [
    "## 12. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"PROJECT SUMMARY AND CONCLUSIONS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\nPROJECT OVERVIEW:\")\n",
    "print(\"-\" * 100)\n",
    "print(f\"• Dataset: {csv_filename}\")\n",
    "print(f\"• Total Samples: {len(df)}\")\n",
    "print(f\"• Features: {X.shape[1]}\")\n",
    "print(f\"• Target Variable: {target_col}\")\n",
    "print(f\"• Models Evaluated: {len(models)}\")\n",
    "\n",
    "print(\"\\n\\nMODEL PERFORMANCE RANKING:\")\n",
    "print(\"-\" * 100)\n",
    "for i, row in results_df.iterrows():\n",
    "    print(f\"{i+1}. {row['Model']:<25} | R²: {row['R²']:.4f} | RMSE: {row['RMSE']:.4f} | MAE: {row['MAE']:.4f}\")\n",
    "\n",
    "print(\"\\n\\nKEY FINDINGS:\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "best = results_df.iloc[0]\n",
    "worst = results_df.iloc[-1]\n",
    "\n",
    "print(f\"\\n1. BEST PERFORMING MODEL:\")\n",
    "print(f\"   Model: {best['Model']}\")\n",
    "print(f\"   R² Score: {best['R²']:.4f}\")\n",
    "print(f\"   RMSE: {best['RMSE']:.4f}\")\n",
    "print(f\"   MAE: {best['MAE']:.4f}\")\n",
    "\n",
    "print(f\"\\n2. WORST PERFORMING MODEL:\")\n",
    "print(f\"   Model: {worst['Model']}\")\n",
    "print(f\"   R² Score: {worst['R²']:.4f}\")\n",
    "print(f\"   RMSE: {worst['RMSE']:.4f}\")\n",
    "\n",
    "print(f\"\\n3. MODEL TYPE COMPARISON:\")\n",
    "linear_r2 = results_df[results_df['Model'].isin(['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'ElasticNet'])]['R²'].mean()\n",
    "print(f\"   Linear Models Average R²: {linear_r2:.4f}\")\n",
    "\n",
    "print(f\"\\n4. FEATURE IMPORTANCE (TOP COEFFICIENTS):\")\n",
    "coefs = trained_models['Linear Regression'].coef_\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': coefs,\n",
    "    'Abs_Coef': np.abs(coefs)\n",
    "}).sort_values('Abs_Coef', ascending=False)\n",
    "\n",
    "print(f\"   Top 3 Most Important Features:\")\n",
    "for idx, (_, row) in enumerate(coef_df.head(3).iterrows(), 1):\n",
    "    print(f\"      {idx}. {row['Feature']}: {row['Coefficient']:+.4f}\")\n",
    "\n",
    "print(f\"\\n5. MODEL RELIABILITY:\")\n",
    "print(f\"   RMSE: {best['RMSE']:.4f}\")\n",
    "print(f\"   MAE: {best['MAE']:.4f}\")\n",
    "print(f\"   MAPE: {best['MAPE (%)']:.2f}%\")\n",
    "avg_target = y_test.mean()\n",
    "rmse_percentage = (best['RMSE'] / avg_target) * 100\n",
    "print(f\"   RMSE as % of mean: {rmse_percentage:.2f}%\")\n",
    "\n",
    "print(f\"\\n6. FEATURE CORRELATIONS WITH TARGET:\")\n",
    "correlations = df.corr()[target_col].sort_values(ascending=False)\n",
    "print(\"   Top 5 correlated features:\")\n",
    "for feature, corr in correlations.items():\n",
    "    if feature != target_col:\n",
    "        print(f\"      {feature}: {corr:+.4f}\")\n",
    "        if len(correlations) - correlations.tolist().index(corr) >= len(correlations) - 5:\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
